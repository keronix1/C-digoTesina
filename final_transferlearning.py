# -*- coding: utf-8 -*-
"""Final_TransferLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sw62UoeEQR-jikDwuzUpMYTsvLLyx5jK
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.data import random_split
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import matplotlib.pyplot as plt
import random
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
from torchvision import models

device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(f'Using device: ', {device})

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/My Drive/CanalesCorrectosImagenes'

!ls '/content/drive/My Drive/CanalesCorrectosImagenes'

transform = transforms.Compose([
        transforms.Resize([224,224]),
        transforms.ToTensor(),
        #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) #calcular la media y la desv. estandar de mis imagenes
        transforms.Normalize([0.229], [0.225])
    ])

full_dataset = datasets.ImageFolder(path, transform=transform)

TRAIN_SIZE =  int(len(full_dataset) * 0.8)
VAL_SIZE = int(len(full_dataset) * 0.1 + 1)
TEST_SIZE = int(len(full_dataset) * 0.1 + 1)
BATCH_SIZE = 16
print(TRAIN_SIZE)
print(VAL_SIZE)
print(TEST_SIZE)

training_set, val_set, test_set = random_split(full_dataset, [TRAIN_SIZE, VAL_SIZE, TEST_SIZE])

training_loader = DataLoader(dataset=training_set, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(dataset=val_set, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True)

for i, (x, y) in enumerate(val_loader):
    print(i, x.shape, y.shape)



from PIL import Image

categories = ['genu valgo', 'genu varo']
def plot_figure(image):
    plt.imshow(image.permute(1,2,0))
    plt.show()

rnd_sample_idx = np.random.randint(0, len(test_set))
print(f'Índice de la imagen muestreada: {rnd_sample_idx}')

sample_label = test_set[rnd_sample_idx][1]
print(f'Etiqueta de la imagen muestreada: {sample_label}')

print(f'La imagen muestreada representa un: {categories[sample_label]}')

image = test_loader.dataset[rnd_sample_idx][0]
image = (image - image.min()) / (image.max() -image.min() )
plot_figure(image)

def accuracy(model, loader):
    num_correct = 0
    num_total = 0
    #establece un modelo de evaluación
    model.eval()
    #sirve para que el modelo se mueva a la GPU
    model = model.to(device=device)
    with torch.no_grad():
        for (xi, yi) in loader:
            xi = xi.to(device=device, dtype = torch.float32)
            yi = yi.to(device=device, dtype = torch.long)
            #modelo se utiliza para predecir las etiquetas de clase para los datos de entrada 
            scores = model(xi) # mb_size, 10
            _, pred = scores.max(dim=1) #pred shape (mb_size )
            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)
            num_total += pred.size(0)

        return float(num_correct)/num_total

"""**Cargar modelo pre-cargado**"""

model_resnet18 = models.resnet18(pretrained=True)

"""**Explorar el modelo**"""

for i, w in enumerate(model_resnet18.parameters()):
    print(i, w.shape, w.requires_grad)

#model_resnet18

"""
**Ajustar a nuestro modelo = Pasa todas las capas que están dentro del modelo de Res, usando secuential haciendo uso de estas capas**"""

model_aux = nn.Sequential(*list(model_resnet18.children()))
#model_aux

"""**No pasa el modelo completo, solamente se quita la última capa**"""

model_aux = nn.Sequential(*list(model_resnet18.children())[:-1])

#model_aux

"""**Para todos los parámetros de este modelo auxiliar, se pondrá requires como false para que los congele**"""

for i, parameter in enumerate(model_aux.parameters()):
    parameter.requires_grad = False

"""**Loop de entrenamiento**

"""

def train(model, optimiser, epochs=100):
#     def train(model, optimiser, scheduler = None, epochs=100):
    model = model.to(device=device)
    for epoch in range(epochs):
      #se iteran el conjunto de datos y se ajusta el modelo y se mueven los datos de entrada y salida
        for (xi, yi) in training_loader:
            model.train()
            xi = xi.to(device=device, dtype=torch.float32)
            yi = yi.to(device=device, dtype=torch.long)
            scores = model(xi)

            #F.cross es una funcion de perdida que se utiliza para la clasificación multiclase
            #cost se utiliza posteriormente para ajustacross entropyr los pesos del modelo utilizando el optimizador
            cost = F.cross_entropy(input= scores, target=yi.squeeze())
        
            optimiser.zero_grad() #borra los gradientes acumulados de los parametros      
            cost.backward() #calculan los gradientes de los parametros del modelo
            optimiser.step() #actualiza los parametros del modelo en funcion de los gradientes     
            
        acc = accuracy(model, val_loader)
        #if epoch%5 == 0:     
        print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy: {acc},')
#         scheduler.step()

"""**checar los epcochs**"""

epochs=50

"""***Modelo y parametros***"""

lr = 0.0833399381863529

model1 = nn.Sequential(model_aux,
                          nn.Flatten(),
                          nn.Linear(in_features=512, out_features=10, bias=True))
optimiser=torch.optim.Adam(model1.parameters(), lr=lr, betas=(0.9,0.999))

print("Learning Rate:", lr)

train(model1, optimiser, epochs)
acc = accuracy(model1, test_loader)
print("Accuracy:", acc)

print("-----------")

"""***F1:SCORE***"""

from sklearn.metrics import f1_score

def f1(model, loader):
    y_true = []
    y_pred = []
    model.eval()
    model = model.to(device=device)
    with torch.no_grad():
        for (xi, yi) in loader:
            xi = xi.to(device=device, dtype=torch.float32)
            yi = yi.to(device=device, dtype=torch.long)
            scores = model(xi)
            _, pred = scores.max(dim=1)
            y_true.extend(yi.squeeze().tolist())
            y_pred.extend(pred.tolist())

    f1 = f1_score(y_true, y_pred)
    return f1

f1_score = f1(model1, test_loader)
print("F1 Score:", f1_score)

***Solución de error al mostrar las imagenes***

def plot_figure(image):
    image = image.clamp(0, 1)  # Asegurar que los valores de los píxeles estén en el rango [0, 1]

    # Mostrar la imagen
    plt.imshow(image.permute(1, 2, 0))
    plt.axis('off')
    plt.show()

"""Resultados en base al modelo"""

model1.eval()  # Establecer el modelo en modo de evaluación
model1 = model1.to(device=device)  # Mover el modelo a la GPU si está disponible

true_labels = []
predicted_labels = []
count = 0
#categories.reverse()

with torch.no_grad():
    correct_predictions = 0
    total_predictions = 0

    for i, (x, y) in enumerate(test_loader):
        x = x.to(device=device, dtype=torch.float32)
        y = y.to(device=device, dtype=torch.long)

        scores = model1(x)  # Obtener las puntuaciones de salida del modelo
        
        _, predictions = scores.max(dim=1)  # Obtener las predicciones

        true_labels.extend(y.cpu().numpy())
        predicted_labels.extend(predictions.cpu().numpy())

        for j in range(len(predictions)):
            if count < 12:
                image = x[j].cpu()  # Mover la imagen a la CPU
                category = categories[predictions[j].item()]  # Obtener la categoría correspondiente a la predicción

                true_label = y[j].item()
                predicted_label = predictions[j].item()

                # Accuracy Imagenes
                is_correct = predicted_label == true_label
                correct_predictions += is_correct
                total_predictions += 1

                is_correct_str = "Correcto" if is_correct else "Incorrecto" #ver si es correcta la imagen
                plot_figure(image)  # Mostrar la imagen
                print("-------------------------------------")
                print(f'Predicción: {category}\n', f'Imagen: {count}\n')
                print(f'Resultado: {is_correct_str}')
                print("-------------------------------------")
            
                count += 1
            else:
                break

accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
print("Accuracy Imagenes:", accuracy)

